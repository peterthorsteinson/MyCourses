{"nbformat_minor": 1, "cells": [{"source": "## Text Analysis\nIn this lab, you will create a classification model that performs sentiment analysis of tweets.\n### Import Spark SQL and Spark ML Libraries\n\nFirst, import the libraries you will need:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.feature.{HashingTF, Tokenizer, StopWordsRemover}", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Load Source Data\nNow load the tweets data into a DataFrame. This data consists of tweets that have been previously captured and classified as positive or negative.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val tweets_csv = spark.read.option(\"inferSchema\",\"true\").option(\"header\", \"true\").csv(\"wasb:///data/tweets.csv\")\ntweets_csv.show(truncate = false)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Prepare the Data\nThe features for the classification model will be derived from the tweet text. The label is the sentiment (1 for positive, 0 for negative)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val data = tweets_csv.select($\"SentimentText\", $\"Sentiment\".cast(\"Int\").alias(\"label\"))\ndata.show(truncate = false)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Split the Data\nIn common with most classification modeling processes, you'll split the data into a set for training, and a set for testing the trained model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val splits = data.randomSplit(Array(0.7, 0.3))\nval train = splits(0)\nval test = splits(1).withColumnRenamed(\"label\", \"trueLabel\")\nval train_rows = train.count()\nval test_rows = test.count()\nprintln(\"Training Rows: \" + train_rows + \" Testing Rows: \" + test_rows)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Define the Pipeline\nThe pipeline for the model consist of the following stages:\n- A Tokenizer to split the tweets into individual words.\n- A StopWordsRemover to remove common words such as \"a\" or \"the\" that have little predictive value.\n- A HashingTF class to generate numeric vectors from the text values.\n- A LogisticRegression algorithm to train a binary classification model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val tokenizer = new Tokenizer().setInputCol(\"SentimentText\").setOutputCol(\"SentimentWords\")\nval swr = new StopWordsRemover().setInputCol(tokenizer.getOutputCol).setOutputCol(\"MeaningfulWords\")\nval hashTF = new HashingTF().setInputCol(swr.getOutputCol).setOutputCol(\"features\")\nval lr = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\").setMaxIter(10).setRegParam(0.01)\nval pipeline = new Pipeline().setStages(Array(tokenizer, swr, hashTF, lr))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Run the Pipeline as an Estimator\nThe pipeline itself is an estimator, and so it has a **fit** method that you can call to run the pipeline on a specified DataFrame. In this case, you will run the pipeline on the training data to train a model. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val piplineModel = pipeline.fit(train)\nprintln(\"Pipeline complete!\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Test the Pipeline Model\nThe model produced by the pipeline is a transformer that will apply all of the stages in the pipeline to a specified DataFrame and apply the trained model to generate predictions. In this case, you will transform the **test** DataFrame using the pipeline to generate label predictions.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val prediction = piplineModel.transform(test)\nval predicted = prediction.select(\"SentimentText\", \"features\", \"prediction\", \"trueLabel\")\npredicted.show(100, truncate = false)", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}