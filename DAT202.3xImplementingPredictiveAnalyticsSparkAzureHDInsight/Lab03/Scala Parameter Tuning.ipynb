{"nbformat_minor": 1, "cells": [{"source": "## Tuning Model Parameters\n\nIn this exercise, you will optimise the parameters for a classification model.\n\n### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "// Import Spark SQL and Spark ML libraries\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n\n// Load the source data\nval csv = spark.read.option(\"inferSchema\",\"true\").option(\"header\", \"true\").csv(\"wasb:///data/flights.csv\")\n\n// Select features and label\nval data = csv.select($\"DayofMonth\", $\"DayOfWeek\", $\"OriginAirportID\", $\"DestAirportID\", $\"DepDelay\", ($\"ArrDelay\" > 15).cast(\"Int\").alias(\"label\"))\n\n// Split the data\nval splits = data.randomSplit(Array(0.7, 0.3))\nval train = splits(0)\nval test = splits(1).withColumnRenamed(\"label\", \"trueLabel\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Define the Pipeline\nNow define a pipeline that creates a feature vector and trains a classification model", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "// Define the pipeline\nval assembler = new VectorAssembler().setInputCols(Array(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\")).setOutputCol(\"features\")\nval lr = new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\")\nval pipeline = new Pipeline().setStages(Array(assembler, lr))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Tune Parameters\nYou can tune parameters to find the best model for your data. A simple way to do this is to use  **TrainValidationSplit** to evaluate each combination of parameters defined in a **ParameterGrid** against a subset of the training data in order to find the best performing parameters.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val paramGrid = new ParamGridBuilder().addGrid(lr.regParam, Array(0.3, 0.1, 0.01)).addGrid(lr.maxIter, Array(10, 5)).addGrid(lr.threshold, Array(0.35, 0.3)).build()\nval tvs = new TrainValidationSplit().setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator).setEstimatorParamMaps(paramGrid).setTrainRatio(0.8)\n\nval model = tvs.fit(train)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Test the Model\nNow you're ready to apply the model to the test data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val prediction = model.transform(test)\nval predicted = prediction.select(\"features\", \"prediction\", \"probability\", \"trueLabel\")\npredicted.show(100)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Compute Confusion Matrix Metrics\nNow you can examine the confusion matrix metrics to judge the performance of the model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val tp = predicted.filter(\"prediction == 1 AND truelabel == 1\").count().toFloat\nval fp = predicted.filter(\"prediction == 1 AND truelabel == 0\").count().toFloat\nval tn = predicted.filter(\"prediction == 0 AND truelabel == 0\").count().toFloat\nval fn = predicted.filter(\"prediction == 0 AND truelabel == 1\").count().toFloat\nval metrics = spark.createDataFrame(Seq(\n (\"TP\", tp),\n (\"FP\", fp),\n (\"TN\", tn),\n (\"FN\", fn),\n (\"Precision\", tp / (tp + fp)),\n (\"Recall\", tp / (tp + fn)))).toDF(\"metric\", \"value\")\nmetrics.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Review the Area Under ROC\nYou can also assess the accuracy of the model by reviewing the area under ROC metric.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val evaluator = new BinaryClassificationEvaluator().setLabelCol(\"trueLabel\").setRawPredictionCol(\"prediction\").setMetricName(\"areaUnderROC\")\nval aur = evaluator.evaluate(prediction)\nprintln(\"AUR = \" + (aur))", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}